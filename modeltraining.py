# -*- coding: utf-8 -*-
"""ModelTraining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18kiXZ4XSttypf9DMr2Rsd-TQVoQ6EBWB
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

df= pd.read_csv("/content/Final_df.csv")

df.shape

df.head()

df.info()

df['Approved_Flag'].value_counts()

label= LabelEncoder()
df['Approved_Flag']= label.fit_transform(df['Approved_Flag'])

df['Approved_Flag'].value_counts()

X= df.drop('Approved_Flag', axis=1)
y= df['Approved_Flag']

reduced_df = df.sample(n=5000, random_state=42) # Set random_state for reproducibility

X_red= reduced_df.drop('Approved_Flag', axis=1)
y_red= reduced_df['Approved_Flag']

X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_red, y_red, test_size=0.2, random_state=42)

scaler= StandardScaler()

scaler.fit(X_train_red)
X_train_red_scaled= scaler.transform(X_train_red)
X_test_red_scaled= scaler.transform(X_test_red)

!pip install lazypredict
from lazypredict.Supervised import LazyClassifier

clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)
models,predictions = clf.fit(X_train_red_scaled, X_test_red_scaled, y_train_red, y_test_red)

models



!pip install lazypredict
from lazypredict.Supervised import LazyClassifier

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler= StandardScaler()
scaler.fit(X_train)
X_train_scaled= scaler.transform(X_train)
X_test_scaled= scaler.transform(X_test)

X_train_scaled.shape

!pip install optuna
!pip install optuna-integration

import optuna
import lightgbm as lgb
from optuna.integration import LightGBMTunerCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def objective(trial):
    param = {
        'objective': 'multiclass',
        'metric': 'multi_logloss',
        'verbosity': -1,
        'boosting_type': 'gbdt',
        'num_class': 4,
        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),
        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),
        'num_leaves': trial.suggest_int('num_leaves', 2, 256),
        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),
        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
    }
    gbm = lgb.LGBMClassifier(**param)
    gbm.fit(X_train_scaled, y_train)

    # Predict on the validation set
    y_pred = gbm.predict(X_test_scaled)

    # Evaluate accuracy and f1_score
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')


    # Return the accuracy as the metric to optimize
    return accuracy

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=25)

print("Best trial:")
trial = study.best_trial

print("  Value (Accuracy): {}".format(trial.value))

print("  Params: ")
for key, value in trial.params.items():
    print("    {}: {}".format(key, value))

best_params = trial.params
model = lgb.LGBMClassifier(**best_params)
model.fit(X_train_scaled, y_train)

!pip install joblib

import joblib
filename = 'credit_risk_model.sav'
joblib.dump(model, filename)
print(f'Model saved as {filename}')

y_pred = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
# Set average='weighted' to handle multiclass classification
f1 = f1_score(y_test, y_pred, average='weighted')
print(f'Test Accuracy: {accuracy:.4f}')
print(f'Test F1 Score: {f1:.4f}')

